#Problem 1: Pt1
import pandas as pd
import numpy as np
import tensorflow as tf
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score


url = "https://raw.githubusercontent.com/HamedTabkhi/Intro-to-ML/refs/heads/main/Dataset/Housing.csv"
data = pd.read_csv(url)

# Categorical columns
categorical_columns = data.select_dtypes(include=['object']).columns

# Convert categorical columns to numeric
data = pd.get_dummies(data, columns=categorical_columns, drop_first=True)


X = data.iloc[:, :-1].values  # Features
y = data.iloc[:, -1].values   # Target

if y.dtype == 'object':
    label_encoder = LabelEncoder()
    y = label_encoder.fit_transform(y)

# Normalizing
scaler = StandardScaler()
X = scaler.fit_transform(X)

# Train-test split
X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)

# NN model
model = tf.keras.Sequential([
    tf.keras.layers.Dense(8, activation='relu', input_shape=(X_train.shape[1],)),
    tf.keras.layers.Dense(1, activation='sigmoid')  # Used sigmoid for binary classification, linear for regression
])


model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Training
import time
start_time = time.time()
history = model.fit(X_train, y_train, epochs=100, validation_data=(X_val, y_val), verbose=1)
training_time = time.time() - start_time

# Plotting training and validation loss
plt.figure(figsize=(10, 5))
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Training and Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.grid()
plt.show()

loss, accuracy = model.evaluate(X_val, y_val, verbose=0)

# Prediction on validation
y_pred = model.predict(X_val).flatten()
y_pred_class = (y_pred > 0.5).astype(int)

precision = precision_score(y_val, y_pred_class, average='weighted')
recall = recall_score(y_val, y_pred_class, average='weighted')
f1 = f1_score(y_val, y_pred_class, average='weighted')

print(f"Problem 1: Pt1")
print(f"Training Time: {training_time:.2f} seconds")
print(f"Test Loss: {loss:.4f}")
print(f"Test Accuracy: {accuracy:.4f}")
print(f"Test Precision: {precision:.4f}")
print(f"Test Recall: {recall:.4f}")
print(f"Test F1 Score: {f1:.4f}")

#Problem 1: Pt2
import pandas as pd
import numpy as np
import tensorflow as tf
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score


url = "https://raw.githubusercontent.com/HamedTabkhi/Intro-to-ML/refs/heads/main/Dataset/Housing.csv"
data = pd.read_csv(url)

# Categorical columns
categorical_columns = data.select_dtypes(include=['object']).columns

# Convert categorical columns to numeric
data = pd.get_dummies(data, columns=categorical_columns, drop_first=True)


X = data.iloc[:, :-1].values  # Features
y = data.iloc[:, -1].values   # Target


if y.dtype == 'object':
    label_encoder = LabelEncoder()
    y = label_encoder.fit_transform(y)

# Normalizing
scaler = StandardScaler()
X = scaler.fit_transform(X)

# Train-test split
X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)

# NN model with three hidden layers
model = tf.keras.Sequential([
    tf.keras.layers.Dense(8, activation='relu', input_shape=(X_train.shape[1],)), #1
    tf.keras.layers.Dense(8, activation='relu'),  #2
    tf.keras.layers.Dense(8, activation='relu'),  #3
    tf.keras.layers.Dense(1, activation='sigmoid')
])

model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Training
import time
start_time = time.time()
history = model.fit(X_train, y_train, epochs=100, validation_data=(X_val, y_val), verbose=1)
training_time = time.time() - start_time

# Plotting training and validation loss
plt.figure(figsize=(10, 5))
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Training and Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.grid()
plt.show()

loss, accuracy = model.evaluate(X_val, y_val, verbose=0)

y_pred = model.predict(X_val).flatten()
y_pred_class = (y_pred > 0.5).astype(int)  # Convert probabilities to binary predictions

precision = precision_score(y_val, y_pred_class, average='weighted')
recall = recall_score(y_val, y_pred_class, average='weighted')
f1 = f1_score(y_val, y_pred_class, average='weighted')

print(f"Problem 1: Pt2")
print(f"Training Time: {training_time:.2f} seconds")
print(f"Test Loss: {loss:.4f}")
print(f"Test Accuracy: {accuracy:.4f}")
print(f"Test Precision: {precision:.4f}")
print(f"Test Recall: {recall:.4f}")
print(f"Test F1 Score: {f1:.4f}")

#Probelm 2: Pt1
import numpy as np
import pandas as pd
import tensorflow as tf
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

from sklearn.datasets import load_breast_cancer
breast = load_breast_cancer()
X = breast.data
y = breast.target


scaler = StandardScaler()
X = scaler.fit_transform(X)


X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)

# NN Model
model = tf.keras.Sequential([
    tf.keras.layers.Dense(32, activation='relu', input_shape=(X_train.shape[1],)),
    tf.keras.layers.Dense(1, activation='sigmoid')
])


model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Training
import time
start_time = time.time()
history = model.fit(X_train, y_train, epochs=100, validation_data=(X_val, y_val), verbose=1)
training_time = time.time() - start_time

# Plotting training and validation loss
plt.figure(figsize=(10, 5))
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Training and Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.grid()
plt.show()

loss, accuracy = model.evaluate(X_val, y_val, verbose=0)


y_pred = model.predict(X_val).flatten()
y_pred_class = (y_pred > 0.5).astype(int)  # Convert probabilities to binary predictions


precision = precision_score(y_val, y_pred_class)
recall = recall_score(y_val, y_pred_class)
f1 = f1_score(y_val, y_pred_class)

print(f"Problem 2: Pt1")
print(f"Training Time: {training_time:.2f} seconds")
print(f"Test Loss: {loss:.4f}")
print(f"Test Accuracy: {accuracy:.4f}")
print(f"Test Precision: {precision:.4f}")
print(f"Test Recall: {recall:.4f}")
print(f"Test F1 Score: {f1:.4f}")

#Problem 2: Pt2
import numpy as np
import pandas as pd
import tensorflow as tf
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

from sklearn.datasets import load_breast_cancer
breast = load_breast_cancer()
X = breast.data
y = breast.target


scaler = StandardScaler()
X = scaler.fit_transform(X)


X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)

# NN model with three hidden layers (32 nodes each)
model = tf.keras.Sequential([
    tf.keras.layers.Dense(32, activation='relu', input_shape=(X_train.shape[1],)),
    tf.keras.layers.Dense(32, activation='relu'),
    tf.keras.layers.Dense(32, activation='relu'),
    tf.keras.layers.Dense(1, activation='sigmoid')
])


model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Training
import time
start_time = time.time()
history = model.fit(X_train, y_train, epochs=100, validation_data=(X_val, y_val), verbose=1)
training_time = time.time() - start_time

# Plotting training and validation loss
plt.figure(figsize=(10, 5))
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Training and Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.grid()
plt.show()

loss, accuracy = model.evaluate(X_val, y_val, verbose=0)


y_pred = model.predict(X_val).flatten()
y_pred_class = (y_pred > 0.5).astype(int)  # Convert prob to binary predict


precision = precision_score(y_val, y_pred_class)
recall = recall_score(y_val, y_pred_class)
f1 = f1_score(y_val, y_pred_class)

print(f"Problem 2: Pt2")
print(f"Training Time: {training_time:.2f} seconds")
print(f"Test Loss: {loss:.4f}")
print(f"Test Accuracy: {accuracy:.4f}")
print(f"Test Precision: {precision:.4f}")
print(f"Test Recall: {recall:.4f}")
print(f"Test F1 Score: {f1:.4f}")

#Problem 3: Pt 1
import numpy as np
import tensorflow as tf
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from tensorflow.keras.datasets import cifar10
from tensorflow.keras.utils import to_categorical
from sklearn.preprocessing import StandardScaler
import time

# CIFAR-10 dataset
(X_train, y_train), (X_test, y_test) = cifar10.load_data()

# Preprocess the data
# Normalizing images to range [0, 1]
X_train, X_test = X_train / 255.0, X_test / 255.0

# Target Labels
y_train = to_categorical(y_train, 10)
y_test = to_categorical(y_test, 10)

# NN Model
model = tf.keras.Sequential([
    tf.keras.layers.Flatten(input_shape=(32, 32, 3)),  # Flattening input (32x32x3) images
    tf.keras.layers.Dense(256, activation='relu'),
    tf.keras.layers.Dense(10, activation='softmax')
])


model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# Training
start_time = time.time()
history = model.fit(X_train, y_train, epochs=100, validation_data=(X_test, y_test), verbose=1)
training_time = time.time() - start_time

# Plotting training and validation loss
plt.figure(figsize=(10, 5))
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Training and Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.grid()
plt.show()

loss, accuracy = model.evaluate(X_test, y_test, verbose=0)

# Predictions
y_pred = model.predict(X_test)
y_pred_class = np.argmax(y_pred, axis=1)
y_test_class = np.argmax(y_test, axis=1)


precision = precision_score(y_test_class, y_pred_class, average='weighted')
recall = recall_score(y_test_class, y_pred_class, average='weighted')
f1 = f1_score(y_test_class, y_pred_class, average='weighted')

print(f"Problem 3: Pt1")
print(f"Training Time: {training_time:.2f} seconds")
print(f"Test Loss: {loss:.4f}")
print(f"Test Accuracy: {accuracy:.4f}")
print(f"Test Precision: {precision:.4f}")
print(f"Test Recall: {recall:.4f}")
print(f"Test F1 Score: {f1:.4f}")

#Problem 3: Part 2
import numpy as np
import tensorflow as tf
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from tensorflow.keras.datasets import cifar10
from tensorflow.keras.utils import to_categorical
import time

# CIFAR-10 dataset
(X_train, y_train), (X_test, y_test) = cifar10.load_data()

# Preprocess the data
# Normalizing images to range [0, 1]
X_train, X_test = X_train / 255.0, X_test / 255.0


y_train = to_categorical(y_train, 10)
y_test = to_categorical(y_test, 10)

# NN model with three hidden layers (256 nodes each)
model = tf.keras.Sequential([
    tf.keras.layers.Flatten(input_shape=(32, 32, 3)),  # Flattening input (32x32x3) images
    tf.keras.layers.Dense(256, activation='relu'),  # 1
    tf.keras.layers.Dense(256, activation='relu'),  # 2
    tf.keras.layers.Dense(256, activation='relu'),  # 3
    tf.keras.layers.Dense(10, activation='softmax')
])


model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# Training
start_time = time.time()
history = model.fit(X_train, y_train, epochs=100, validation_data=(X_test, y_test), verbose=1)
training_time = time.time() - start_time

# Plotting training and validation loss
plt.figure(figsize=(10, 5))
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Training and Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.grid()
plt.show()

loss, accuracy = model.evaluate(X_test, y_test, verbose=0)

# Predictions
y_pred = model.predict(X_test)
y_pred_class = np.argmax(y_pred, axis=1)
y_test_class = np.argmax(y_test, axis=1)

precision = precision_score(y_test_class, y_pred_class, average='weighted')
recall = recall_score(y_test_class, y_pred_class, average='weighted')
f1 = f1_score(y_test_class, y_pred_class, average='weighted')

print(f"Problem 3: Pt2")
print(f"Training Time: {training_time:.2f} seconds")
print(f"Test Loss: {loss:.4f}")
print(f"Test Accuracy: {accuracy:.4f}")
print(f"Test Precision: {precision:.4f}")
print(f"Test Recall: {recall:.4f}")
print(f"Test F1 Score: {f1:.4f}")
